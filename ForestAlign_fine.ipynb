{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6d0ba0-303b-4be5-92c9-cf0a7495df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from sklearn.cluster import DBSCAN, MeanShift\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import ConvexHull, cKDTree\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44490dc5-1e05-4c1c-b617-be88819dda8b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7f98f8-970d-4ac0-9b35-a3fbe9dd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voxel_grid(point_cloud, voxel_size):\n",
    "    points_np = np.asarray(point_cloud.points)  # Convert points to a NumPy array\n",
    "    min_bound = np.min(points_np, axis=0)\n",
    "    \n",
    "    # Compute voxel indices for all points at once using vectorized operations\n",
    "    voxel_indices = np.floor((points_np - min_bound) / voxel_size).astype(int)\n",
    "\n",
    "    # Create a dictionary mapping each voxel to its list of point indices\n",
    "    voxel_grid = {}\n",
    "    for i, voxel_index in enumerate(map(tuple, voxel_indices)):  # tuple to use as dict key\n",
    "        voxel_grid.setdefault(voxel_index, []).append(i)\n",
    "\n",
    "    return voxel_grid\n",
    "\n",
    "def calculate_voxel_centers(point_cloud, voxel_grid):\n",
    "    points_np = np.asarray(point_cloud.points)  # Convert once outside the loop\n",
    "    voxel_centers = {}\n",
    "\n",
    "    for voxel_index, point_indices in voxel_grid.items():\n",
    "        points = points_np[point_indices]  # Indexing directly from the pre-converted NumPy array\n",
    "        gravity_center = np.mean(points, axis=0)\n",
    "        voxel_centers[voxel_index] = gravity_center\n",
    "\n",
    "    return voxel_centers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a80184a1-835f-4338-bb6f-e2d4cec3dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correspondences(tls_points, dls_points):\n",
    "    # Find the nearest neighbors between TLS and DLS points\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(dls_points)\n",
    "    distances, indices = nbrs.kneighbors(tls_points)\n",
    "\n",
    "    # Return the correspondences as a dictionary\n",
    "    correspondences = {'tls_indices': np.arange(len(tls_points)), 'dls_indices': indices.flatten()}\n",
    "\n",
    "    return correspondences\n",
    "\n",
    "\n",
    "def estimate_transformation(correspondences, tls_valid_p, dls_valid_p):\n",
    "    tls_indices = correspondences['tls_indices']\n",
    "    dls_indices = correspondences['dls_indices']\n",
    "\n",
    "    # Use NumPy array indexing instead of list comprehension for better performance\n",
    "    dls_points_matched = np.array(dls_valid_p)[dls_indices]\n",
    "    tls_points_matched = np.array(tls_valid_p)[tls_indices]\n",
    "\n",
    "    # Calculate centroids of the matched point pairs\n",
    "    centroid_dls = np.mean(dls_points_matched, axis=0)\n",
    "    centroid_tls = np.mean(tls_points_matched, axis=0)\n",
    "\n",
    "    # Construct matrix H\n",
    "    H = np.dot((dls_points_matched - centroid_dls).T, (tls_points_matched - centroid_tls))\n",
    "    \n",
    "    # Compute SVD to estimate rotation matrix R\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "    \n",
    "    # Ensure no reflection by checking the determinant\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = np.dot(Vt.T, U.T)\n",
    "    \n",
    "    # Calculate translation vector t\n",
    "    t = centroid_tls - np.dot(R, centroid_dls)\n",
    "\n",
    "    # Construct transformation matrix\n",
    "    transformation = np.eye(4)\n",
    "    transformation[:3, :3] = R\n",
    "    transformation[:3, 3] = t\n",
    "\n",
    "    return transformation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_convergence(iteration, current_rmse):\n",
    "    # Check convergence condition based on a threshold or criteria\n",
    "    # Here's a placeholder example that checks if the registration has converged\n",
    "    # based on the maximum number of iterations or a threshold difference in RMSE\n",
    "    max_iterations = 15\n",
    "    threshold_rmse = 0.01\n",
    "\n",
    "    # Additional logic to determine convergence based on your criteria\n",
    "    # You can modify or replace this condition according to your requirements\n",
    "    if iteration >= max_iterations or current_rmse < threshold_rmse:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def axis_angle_to_matrix(axis, theta):\n",
    "    #skwed object matrix\n",
    "    w = np.array([[ 0.0, -axis[2], axis[1]],\n",
    "                   [axis[2], 0.0, -axis[0]],\n",
    "                  [-axis[1], axis[0], 0.0]\n",
    "    ])\n",
    "    \n",
    "    rot = np.identity(3) + (np.sin(theta)*w) \\\n",
    "    + ((1-np.cos(theta))*np.dot(w,w))\n",
    "    \n",
    "    return rot\n",
    "\n",
    "\n",
    "\n",
    "def calculate_distances(tls_gravity_points, dls_gravity_points):\n",
    "    # Calculate distances between TLS and DLS gravity center points in each voxel\n",
    "    distances = {}\n",
    "    for voxel_index in tls_gravity_points.keys():\n",
    "        tls_gravity_center = tls_gravity_points[voxel_index]\n",
    "        dls_gravity_center = dls_gravity_points.get(voxel_index)\n",
    "\n",
    "        if dls_gravity_center is not None and dls_gravity_center.size > 0:\n",
    "            distance = np.linalg.norm(tls_gravity_center - dls_gravity_center)\n",
    "            distances[voxel_index] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ade9e8-f819-4528-af41-a79cd339302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gravity_centers(voxel_indices, tls_ds_points, dls_ds_points, min_bound):\n",
    "    tls_voxel_points, dls_voxel_points = {}, {}\n",
    "\n",
    "    tls_ds_points_np = np.array(tls_ds_points)\n",
    "    dls_ds_points_np = np.array(dls_ds_points)\n",
    "\n",
    "    for voxel_index in voxel_indices:\n",
    "        size = voxel_index[3]\n",
    "        x_min, x_max = voxel_index[0] * voxel_default_size + min_bound[0], voxel_index[0] * voxel_default_size + min_bound[0] + size\n",
    "        y_min, y_max = voxel_index[1] * voxel_default_size + min_bound[1], voxel_index[1] * voxel_default_size + min_bound[1] + size\n",
    "        z_min, z_max = voxel_index[2] * voxel_default_size + min_bound[2], voxel_index[2] * voxel_default_size + min_bound[2] + size\n",
    "        \n",
    "        # filter out points\n",
    "        tls_mask = (tls_ds_points_np[:, 0] >= x_min) & (tls_ds_points_np[:, 0] <= x_max) & \\\n",
    "                   (tls_ds_points_np[:, 1] >= y_min) & (tls_ds_points_np[:, 1] <= y_max) & \\\n",
    "                   (tls_ds_points_np[:, 2] >= z_min) & (tls_ds_points_np[:, 2] <= z_max)\n",
    "        dls_mask = (dls_ds_points_np[:, 0] >= x_min) & (dls_ds_points_np[:, 0] <= x_max) & \\\n",
    "                   (dls_ds_points_np[:, 1] >= y_min) & (dls_ds_points_np[:, 1] <= y_max) & \\\n",
    "                   (dls_ds_points_np[:, 2] >= z_min) & (dls_ds_points_np[:, 2] <= z_max)\n",
    "\n",
    "        # calculate gravity points\n",
    "        if np.any(tls_mask):\n",
    "            tls_voxel_points[voxel_index] = np.mean(tls_ds_points_np[tls_mask], axis=0)\n",
    "        if np.any(dls_mask):\n",
    "            dls_voxel_points[voxel_index] = np.mean(dls_ds_points_np[dls_mask], axis=0)\n",
    "\n",
    "    return tls_voxel_points, dls_voxel_points\n",
    "\n",
    "\n",
    "def calculate_gravity_centers_optimized(voxel_indices, tls_points, dls_points, min_bound):\n",
    "\n",
    "    tls_points = np.array(tls_points) \n",
    "    dls_points = np.array(dls_points) \n",
    "    sorted_tlsp = tls_points[tls_points[:, 0].argsort()]\n",
    "    sorted_dlsp = dls_points[dls_points[:, 0].argsort()]\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate gravity centers for TLS and DLS points in each voxel and store points in each voxel.\n",
    "\n",
    "    :param voxel_indices: A set of voxel indices to process, each with xyz coordinates and size.\n",
    "    :param tls_points: TLS points as a numpy array.\n",
    "    :param dls_points: DLS points as a numpy array.\n",
    "    :param min_bound: The minimum bounding coordinates of the point cloud.\n",
    "    :return: Three objects - two dictionaries containing the gravity centers of TLS and DLS points for each voxel,\n",
    "             and a dictionary containing points in each voxel.\n",
    "    \"\"\"\n",
    "    tls_voxel_gravity_centers = {}  # Gravity centers for TLS\n",
    "    dls_voxel_gravity_centers = {}  # Gravity centers for DLS\n",
    "    vtls_points = {}  # TLS points in each voxel\n",
    "    vdls_points = {}  # DLS points in each voxel\n",
    "    \n",
    "    for voxel_index in voxel_indices:\n",
    "        size = voxel_index[3]\n",
    "        x_min, x_max = voxel_index[0] * voxel_default_size + min_bound[0], voxel_index[0] * voxel_default_size + min_bound[0] + size\n",
    "        y_min, y_max = voxel_index[1] * voxel_default_size + min_bound[1], voxel_index[1] * voxel_default_size + min_bound[1] + size\n",
    "        z_min, z_max = voxel_index[2] * voxel_default_size + min_bound[2], voxel_index[2] * voxel_default_size + min_bound[2] + size\n",
    "        \n",
    "        # find TLS and DLS points in each voxel\n",
    "        voxel_tls_points = find_points_in_voxel(sorted_tlsp, x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "        voxel_dls_points = find_points_in_voxel(sorted_dlsp, x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "        vtls_points[voxel_index] = voxel_tls_points\n",
    "        vdls_points[voxel_index] = voxel_dls_points\n",
    "\n",
    "\n",
    "        # Calculate and store gravity centers\n",
    "        if len(voxel_tls_points) > 0:\n",
    "            tls_voxel_gravity_centers[voxel_index] = np.mean(voxel_tls_points, axis=0)\n",
    "        if len(voxel_dls_points) > 0:\n",
    "            dls_voxel_gravity_centers[voxel_index] = np.mean(voxel_dls_points, axis=0)\n",
    "\n",
    "    return tls_voxel_gravity_centers, dls_voxel_gravity_centers, vtls_points, vdls_points\n",
    "\n",
    "def find_points_in_voxel(sorted_points, x_min, x_max, y_min, y_max, z_min, z_max):\n",
    "    \n",
    "    sorted_points = sorted_points[sorted_points[:, 0].argsort()]\n",
    "\n",
    "    # bisection for x coordinate\n",
    "    x_min_index = np.searchsorted(sorted_points[:, 0], x_min, side='right')\n",
    "    x_max_index = np.searchsorted(sorted_points[:, 0], x_max, side='left')\n",
    "    x_range_points = sorted_points[x_min_index:x_max_index]\n",
    "    x_range_points = x_range_points[x_range_points[:, 1].argsort()]\n",
    "\n",
    "    # for y\n",
    "    y_min_index = np.searchsorted(x_range_points[:, 1], y_min, side='right')\n",
    "    y_max_index = np.searchsorted(x_range_points[:, 1], y_max, side='left')\n",
    "    y_range_points = x_range_points[y_min_index:y_max_index]\n",
    "    y_range_points = y_range_points[y_range_points[:, 2].argsort()]\n",
    "\n",
    "    # for z\n",
    "    z_min_index = np.searchsorted(y_range_points[:, 2], z_min, side='right')\n",
    "    z_max_index = np.searchsorted(y_range_points[:, 2], z_max, side='left')\n",
    "    voxel_points = y_range_points[z_min_index:z_max_index]\n",
    "\n",
    "    return voxel_points\n",
    "\n",
    "\n",
    "def determine_confidence(voxel_distances, voxels_with_sizes):\n",
    "    \"\"\"\n",
    "    Determine the confidence of each voxel based on the distance between gravity centers and the voxel size.\n",
    "\n",
    "    :param voxel_distances: A dictionary with voxel indices as keys and distances as values.\n",
    "    :param voxels_with_sizes: A set of voxel indices with their sizes, used to calculate the threshold.\n",
    "    :return: Two sets containing confident and unconfident voxel indices.\n",
    "    \"\"\"\n",
    "    confident_voxels = set()\n",
    "    unconfident_voxels = set()\n",
    "\n",
    "    for voxel in voxels_with_sizes:\n",
    "        distance = voxel_distances.get(voxel, float('inf'))\n",
    "        threshold = (np.sqrt(3) / 4) * voxel[3]  # threshold can be reset\n",
    "        #threshold = .5\n",
    "\n",
    "        if distance <= threshold:\n",
    "            confident_voxels.add(voxel)\n",
    "        else:\n",
    "            unconfident_voxels.add(voxel)\n",
    "\n",
    "    return confident_voxels, unconfident_voxels\n",
    "\n",
    "\n",
    "\n",
    "def split_voxels(unconfident_voxels, updated_voxels, voxel_default_size):\n",
    "    \"\"\"\n",
    "    Split the unconfident voxels into smaller voxels and update the voxel set.\n",
    "\n",
    "    :param unconfident_voxels: A set of unconfident voxel indices.\n",
    "    :param updated_voxels: The current set of all voxel indices.\n",
    "    :param voxel_default_size: The current size of each voxel.\n",
    "    :return: The updated set of all voxel indices and the new set of unconfident voxels.\n",
    "    \"\"\"\n",
    "    unconfident_voxels_copy = set(unconfident_voxels)  # duplicate unconf voxels\n",
    "    for voxel in unconfident_voxels:\n",
    "        i, j, k, voxel_size = voxel\n",
    "\n",
    "        # remove unconf\n",
    "        updated_voxels.remove(voxel)\n",
    "        unconfident_voxels_copy.remove(voxel)\n",
    "\n",
    "        # split unconf\n",
    "        new_size = voxel_size / 2.0\n",
    "        size_ratio = new_size / voxel_default_size\n",
    "\n",
    "        for di in range(2):\n",
    "            for dj in range(2):\n",
    "                for dk in range(2):\n",
    "                    new_voxel_index = (i + di * size_ratio, j + dj * size_ratio, k + dk * size_ratio, new_size)\n",
    "                    updated_voxels.add(new_voxel_index)\n",
    "\n",
    "    return updated_voxels, unconfident_voxels_copy\n",
    "\n",
    "def filter_splitable_voxels(unconfident_voxels, min_voxel_size):\n",
    "    \"\"\"\n",
    "    Filter out unconfident voxels that are small enough and should not be split further.\n",
    "\n",
    "    :param unconfident_voxels: A set of unconfident voxel indices.\n",
    "    :param min_voxel_size: The minimum voxel size threshold.\n",
    "    :return: Two sets, one containing voxels to be split and another containing voxels not to be split.\n",
    "    \"\"\"\n",
    "    splitable_voxels = set()\n",
    "    non_splitable_voxels = set()\n",
    "\n",
    "    for voxel in unconfident_voxels:\n",
    "        if voxel[3] > min_voxel_size:\n",
    "            splitable_voxels.add(voxel)\n",
    "        else:\n",
    "            non_splitable_voxels.add(voxel)\n",
    "\n",
    "    return splitable_voxels, non_splitable_voxels\n",
    "\n",
    "\n",
    "def filter_points_by_voxels(tls_points, dls_points, confident_voxels, voxel_default_size, min_bound):\n",
    "    \"\"\"\n",
    "    Filter points from TLS and DLS point clouds that are within the confident voxels.\n",
    "\n",
    "    :param tls_points: TLS points as a numpy array.\n",
    "    :param dls_points: DLS points as a numpy array.\n",
    "    :param confident_voxels: A set of voxel indices that are considered confident.\n",
    "    :param voxel_default_size: The size of each voxel.\n",
    "    :param min_bound: The minimum bounding coordinates of the point cloud.\n",
    "    :return: Two lists containing the filtered points from TLS and DLS point clouds.\n",
    "    \"\"\"\n",
    "    conf_tls_points = []\n",
    "    conf_dls_points = []\n",
    "\n",
    "    tls_points_np = np.array(tls_points)\n",
    "    dls_points_np = np.array(dls_points)\n",
    "\n",
    "    for voxel_index in confident_voxels:\n",
    "        size = voxel_index[-1]\n",
    "        x_min, x_max = voxel_index[0] * voxel_default_size + min_bound[0], voxel_index[0] * voxel_default_size + size + min_bound[0]\n",
    "        y_min, y_max = voxel_index[1] * voxel_default_size + min_bound[1], voxel_index[1] * voxel_default_size + size + min_bound[1]\n",
    "        z_min, z_max = voxel_index[2] * voxel_default_size + min_bound[2], voxel_index[2] * voxel_default_size + size + min_bound[2]\n",
    "\n",
    "        # TLS\n",
    "        tls_mask = (tls_points_np[:, 0] >= x_min) & (tls_points_np[:, 0] <= x_max) & \\\n",
    "                   (tls_points_np[:, 1] >= y_min) & (tls_points_np[:, 1] <= y_max) & \\\n",
    "                   (tls_points_np[:, 2] >= z_min) & (tls_points_np[:, 2] <= z_max)\n",
    "        conf_tls_points.extend(tls_points_np[tls_mask].tolist())\n",
    "\n",
    "        # DLS\n",
    "        dls_mask = (dls_points_np[:, 0] >= x_min) & (dls_points_np[:, 0] <= x_max) & \\\n",
    "                   (dls_points_np[:, 1] >= y_min) & (dls_points_np[:, 1] <= y_max) & \\\n",
    "                   (dls_points_np[:, 2] >= z_min) & (dls_points_np[:, 2] <= z_max)\n",
    "        conf_dls_points.extend(dls_points_np[dls_mask].tolist())\n",
    "\n",
    "    return conf_tls_points, conf_dls_points\n",
    "\n",
    "def extract_confident_points(vtls_points, vdls_points, confident_voxels):\n",
    "    \"\"\"\n",
    "    Extract confident points from voxel points dictionaries based on confident voxels.\n",
    "\n",
    "    :param vtls_points: A dictionary containing TLS points in each voxel.\n",
    "    :param vdls_points: A dictionary containing DLS points in each voxel.\n",
    "    :param confident_voxels: A set of voxel indices that are considered confident.\n",
    "    :return: Two numpy arrays containing the filtered points from TLS and DLS point clouds.\n",
    "    \"\"\"\n",
    "    conf_tls_points = []\n",
    "    conf_dls_points = []\n",
    "\n",
    "    for voxel_index in confident_voxels:\n",
    "        tls_points_in_voxel = vtls_points.get(voxel_index, [])\n",
    "        dls_points_in_voxel = vdls_points.get(voxel_index, [])\n",
    "\n",
    "        conf_tls_points.extend(tls_points_in_voxel)\n",
    "        conf_dls_points.extend(dls_points_in_voxel)\n",
    "\n",
    "    return np.array(conf_tls_points), np.array(conf_dls_points)\n",
    "\n",
    "\n",
    "def calculate_matched_rmse(source_points, target_points):\n",
    "    # find the nearest point in the target points of each point in source_points\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(target_points)\n",
    "    distances, indices = nbrs.kneighbors(source_points)\n",
    "\n",
    "    # matching\n",
    "    matched_target_points = target_points[indices.flatten()]\n",
    "\n",
    "    # RMSE\n",
    "    return np.sqrt(mean_squared_error(source_points, matched_target_points))\n",
    "\n",
    "\n",
    "def find_correspondences(tls_points, dls_points):\n",
    "    # Find the nearest neighbors between TLS and DLS points\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(dls_points)\n",
    "    distances, indices = nbrs.kneighbors(tls_points)\n",
    "\n",
    "    # Return the correspondences as a dictionary\n",
    "    correspondences = {'tls_indices': np.arange(len(tls_points)), 'dls_indices': indices.flatten()}\n",
    "\n",
    "    return correspondences\n",
    "\n",
    "\n",
    "\n",
    "def apply_transformation(points, transformation):\n",
    "    # Apply transformation to points directly without using .T\n",
    "    transformed_points = points @ transformation[:3, :3].T + transformation[:3, 3]\n",
    "    return transformed_points\n",
    "\n",
    "\n",
    "def visualize_confident_points(tls_points, dls_points):\n",
    "    \"\"\"\n",
    "    Visualize TLS and DLS points that are determined as confident.\n",
    "\n",
    "    :param tls_points: TLS points.\n",
    "    :param dls_points: DLS points.\n",
    "    \"\"\"\n",
    "    tls_cloud = o3d.geometry.PointCloud()\n",
    "    tls_cloud.points = o3d.utility.Vector3dVector(tls_points)\n",
    "    tls_cloud.paint_uniform_color([1, 0, 0])  # 红色\n",
    "\n",
    "    dls_cloud = o3d.geometry.PointCloud()\n",
    "    dls_cloud.points = o3d.utility.Vector3dVector(dls_points)\n",
    "    dls_cloud.paint_uniform_color([0, 1, 0])  # 绿色\n",
    "\n",
    "    o3d.visualization.draw_geometries([tls_cloud, dls_cloud])\n",
    "\n",
    "\n",
    "def generate_alpha_shape(raw_points, alpha):\n",
    "    # Step 1: Create a PointCloud from the raw TLS point data\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(raw_points)\n",
    "\n",
    "    # Step 2: Generate the alpha shape\n",
    "    alpha_shape = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha)\n",
    "\n",
    "    # Step 3: Save the alpha shape as a PLY file\n",
    "    #o3d.io.write_triangle_mesh(\"alpha_shape.ply\", alpha_shape)\n",
    "\n",
    "    return alpha_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d447479-1cb7-4936-aa6c-5e78aa731773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_plane_icp_knn(source_points):\n",
    "    closest_points = []\n",
    "    closest_triangle_normals = []\n",
    "    \n",
    "    # Precompute closest points and their normals\n",
    "    for point in source_points:\n",
    "        query_point = o3d.core.Tensor([point], dtype=o3d.core.Dtype.Float32)\n",
    "        result = scene.compute_closest_points(query_point)\n",
    "        closest_points.append(result['points'].numpy()[0])\n",
    "        triangle_idx = result['primitive_ids'].numpy()[0]\n",
    "        closest_triangle_normals.append(np.asarray(triangles_normals)[triangle_idx])\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    closest_points = np.array(closest_points)\n",
    "    closest_triangle_normals = np.array(closest_triangle_normals)\n",
    "    \n",
    "    # Compute point-to-plane distances\n",
    "    point2mesh_dist = np.linalg.norm(source_points - closest_points, axis=1)\n",
    "\n",
    "    # Build the A and b matrices for point-to-plane minimization\n",
    "    np_pcd_s = np.array(source_points)\n",
    "    A = np.zeros((6, 6))\n",
    "    b = np.zeros((6, 1))\n",
    "    \n",
    "    for i in range(len(np_pcd_s)):\n",
    "        xn = np.cross(np_pcd_s[i], closest_triangle_normals[i])\n",
    "        xn_n = np.hstack((xn, closest_triangle_normals[i])).reshape(-1, 1)\n",
    "        A += np.dot(xn_n, xn_n.T)\n",
    "        \n",
    "        nT = closest_triangle_normals[i].reshape(1, -1)\n",
    "        p_x = (closest_points[i] - np_pcd_s[i]).reshape(-1, 1)\n",
    "        b += xn_n * np.dot(nT, p_x)\n",
    "\n",
    "    u_opt = np.linalg.solve(A, b)\n",
    "    theta = np.linalg.norm(u_opt[:3])\n",
    "    w = u_opt[:3].flatten() / theta\n",
    "    rot = axis_angle_to_matrix(w, theta)\n",
    "    \n",
    "    # Construct transformation matrix\n",
    "    transformation = np.eye(4)\n",
    "    transformation[:3, :3] = rot\n",
    "    transformation[:3, 3] = u_opt[3:6].flatten()\n",
    "\n",
    "    # Calculate mean distance\n",
    "    distances = np.abs(np.sum((np_pcd_s - closest_points) * closest_triangle_normals, axis=1))\n",
    "    mean_distance = np.mean(distances)\n",
    "\n",
    "    return transformation, mean_distance\n",
    "\n",
    "\n",
    "\n",
    "def iterative_icp_process_pt2pl(tls_p, dls_p, initial_v, tls_ds_points, dls_ds_points, min_bound, voxel_default_size, max_iterations=15):\n",
    "    # Ensure the point clouds are NumPy arrays\n",
    "    tls_ds_points = np.array(tls_ds_points)\n",
    "    dls_ds_points = np.array(dls_ds_points)\n",
    "    \n",
    "    # Initialize variables\n",
    "    converged = False\n",
    "    transformation = np.eye(4)\n",
    "    iteration = 0\n",
    "    updated_voxels = initial_v\n",
    "    final_confident_tls_points, final_confident_dls_points = [], []\n",
    "    \n",
    "    # Initial gravity centers calculation\n",
    "    tls_gp, dls_gp, vtls_points, vdls_points = calculate_gravity_centers_optimized(updated_voxels, tls_ds_points, dls_ds_points, min_bound)\n",
    "    print('Initial voxel count TLS:', len(vtls_points.keys()), 'DLS:', len(vdls_points.keys()))\n",
    "    \n",
    "    \n",
    "    while not converged:\n",
    "        # Calculate distances between gravity centers\n",
    "        vdist_icp = calculate_distances(tls_gp, dls_gp)\n",
    "        conf_v_icp, unconf_v_icp = determine_confidence(vdist_icp, updated_voxels)\n",
    "        print('Confident and unconfident before splitting:', len(conf_v_icp), len(unconf_v_icp))\n",
    "        \n",
    "        # Split unconfident voxels if needed\n",
    "        splitable_voxels, _ = filter_splitable_voxels(unconf_v_icp, MIN_VOXEL_SIZE)\n",
    "        updated_voxels, _ = split_voxels(splitable_voxels, updated_voxels, voxel_default_size)\n",
    "        \n",
    "        # If no confident voxels, continue to next iteration\n",
    "        if len(conf_v_icp) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Extract confident points\n",
    "        conf_tlsp_icp, conf_dlsp_icp = extract_confident_points(vtls_points, vdls_points, conf_v_icp)\n",
    "        conf_tlsp_icp = np.array(conf_tlsp_icp)\n",
    "        conf_dlsp_icp = np.array(conf_dlsp_icp)\n",
    "        print('Confident TLS:', len(conf_tlsp_icp), 'Confident DLS:', len(conf_dlsp_icp))\n",
    "        \n",
    "        # Perform point-to-plane ICP\n",
    "        transformation, pt2pl_rmse = point_to_plane_icp_knn(conf_dlsp_icp)\n",
    "        conf_dlsp_icp = apply_transformation(conf_dlsp_icp, transformation)\n",
    "        \n",
    "        # Apply the transformation to DLS point cloud and downsampled DLS points\n",
    "        dls_ds_points = apply_transformation(dls_ds_points, transformation)\n",
    "        \n",
    "        # Recalculate gravity centers for updated point cloud\n",
    "        tls_gp, dls_gp, vtls_points, vdls_points = calculate_gravity_centers_optimized(updated_voxels, tls_ds_points, dls_ds_points, min_bound)\n",
    "        \n",
    "        # Compute RMSE between matched points\n",
    "        pt2pt_rmse = calculate_matched_rmse(conf_dlsp_icp, conf_tlsp_icp)\n",
    "        \n",
    "        # Check convergence based on RMSE\n",
    "        converged = check_convergence(iteration, pt2pl_rmse)\n",
    "        \n",
    "        if converged:\n",
    "            print('FINISHED. pt2ptRMSE:', pt2pt_rmse, 'pt2plRMSE:', pt2pl_rmse)\n",
    "            final_confident_tls_points, final_confident_dls_points = conf_tlsp_icp, conf_dlsp_icp\n",
    "            break\n",
    "        \n",
    "        iteration += 1\n",
    "        print('Iteration:', iteration, 'pt2ptRMSE:', pt2pt_rmse, 'pt2plRMSE:', pt2pl_rmse)\n",
    "\n",
    "    return transformation, iteration, final_confident_tls_points, final_confident_dls_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db24b7-b56d-47e4-80a8-3d6d775629a4",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b9390-f213-4dd0-a9d8-165cc75d6fe7",
   "metadata": {},
   "source": [
    "### initial voxelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd7eba-8d24-4044-ada0-c0be5d81edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pcd\n",
    "tls_raw = o3d.io.read_point_cloud(\"your path\")\n",
    "dls_raw = o3d.io.read_point_cloud(\"your path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3702a5-2a3d-49b0-8102-384760c3a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial voxels\n",
    "voxel_size = .5\n",
    "voxel_size_ds = 0.001\n",
    "\n",
    "tls_voxel_grid = create_voxel_grid(tls_raw, voxel_size)\n",
    "dls_voxel_grid = create_voxel_grid(dls_raw, voxel_size)\n",
    "\n",
    "# compute gravity center\n",
    "tls_voxel_centers = calculate_voxel_centers(tls_raw, tls_voxel_grid)\n",
    "dls_voxel_centers = calculate_voxel_centers(dls_raw, dls_voxel_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ca357-ded9-4279-9ef3-35a6225b45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two pcds\n",
    "merged_cloud = tls_raw + dls_raw\n",
    "\n",
    "# boundary\n",
    "min_bound = np.min(np.asarray(merged_cloud.points), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5563e-e408-4b0a-8b4a-86c73bde0b9e",
   "metadata": {},
   "source": [
    "### meshing on TLS pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3f576-9265-4317-b4b4-a9aabe1c5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming tls_voxel_grid and dls_voxel_grid are already computed\n",
    "tls_keys = set(tls_voxel_grid.keys())\n",
    "dls_keys = set(dls_voxel_grid.keys())\n",
    "\n",
    "intersection_keys = tls_keys.intersection(dls_keys)\n",
    "\n",
    "# Replace \"tls_raw.points\" with your actual raw TLS point data\n",
    "tls_alpha_shape = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(tls_raw, alpha=0.05)\n",
    "\n",
    "# create TLS alpha shape\n",
    "tls_alpha_shape = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(tls_raw, alpha=0.05)\n",
    "tls_alpha_shape.compute_triangle_normals()\n",
    "\n",
    "# Access the triangles and triangle normals\n",
    "triangles = tls_alpha_shape.triangles\n",
    "triangles_normals = tls_alpha_shape.triangle_normals\n",
    "\n",
    "# legacy mesh to Tensor mesh\n",
    "tls_alpha_t = o3d.t.geometry.TriangleMesh.from_legacy(tls_alpha_shape)\n",
    "scene = o3d.t.geometry.RaycastingScene()\n",
    "\n",
    "mesh_id = scene.add_triangles(tls_alpha_t)\n",
    "mesh_ids = {mesh_id: 'tls mesh'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ae5ab-5a2e-451c-a391-8b4acb5f0700",
   "metadata": {},
   "source": [
    "### fine registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2e69a-880c-4979-a166-b46df49dd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial voxel size\n",
    "voxel_default_size = voxel_size\n",
    "\n",
    "# Initialize point cloud data, directly using NumPy arrays (no need to convert to lists)\n",
    "tls_points = np.asarray(tls_raw.points)\n",
    "dls_points = np.asarray(dls_raw.points)\n",
    "\n",
    "# Find the intersection of TLS and DLS voxel centers\n",
    "intersection_voxels = set(tls_voxel_centers.keys()) & set(dls_voxel_centers.keys())\n",
    "\n",
    "# Create a new matrix containing the xyz coordinates of each voxel and the initial voxel size\n",
    "initial_voxels = {(x, y, z, voxel_default_size) for (x, y, z) in intersection_voxels}\n",
    "\n",
    "# Update gravity centers using calculate_gravity_centers\n",
    "tls_gp, dls_gp, vtls_points_gp, vdls_points_gp = calculate_gravity_centers_optimized(initial_voxels, tls_points, dls_points, min_bound)\n",
    "\n",
    "# Compute distances between the gravity centers\n",
    "vdist = calculate_distances(tls_gp, dls_gp)\n",
    "\n",
    "# Use vdist directly, no need to create an additional alias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d4690-57f0-484c-befc-3a2591ec2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set minimum voxel size\n",
    "MIN_VOXEL_SIZE = voxel_default_size / (2 ** 4)\n",
    "\n",
    "# No need for deepcopy unless modifying internal structure\n",
    "initial_voxels_in = initial_voxels.copy()\n",
    "\n",
    "# Convert point clouds to NumPy arrays once and reuse\n",
    "tls_points_np = np.asarray(tls_raw.points)\n",
    "dls_points_np = np.asarray(dls_raw.points)\n",
    "\n",
    "# Execute iterative point-to-plane ICP with alpha = 0.1\n",
    "transformation, num_iterations, confident_tls_points, confident_dls_points = iterative_icp_process_pt2pl(\n",
    "    tls_points_np, dls_points_np, initial_voxels_in, tls_points, dls_points, \n",
    "    min_bound, voxel_default_size, max_iterations=15\n",
    ")\n",
    "\n",
    "# Print the transformation results\n",
    "print(\"Transformation Matrix:\")\n",
    "print(transformation)\n",
    "print(\"Number of Iterations:\", num_iterations)\n",
    "\n",
    "# Visualize confident points after convergence\n",
    "visualize_confident_points(confident_tls_points, confident_dls_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55dcd4-9aa5-4f97-8733-9607705013b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
