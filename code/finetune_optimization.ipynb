{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf4254-cad2-4b65-bf96-428ffce36bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ForAlign: An optimization algorithm for forest point cloud registration (Notebook Version)\n",
    "# Fine Alignment algorithm\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from sklearn.cluster import DBSCAN, MeanShift\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial import ConvexHull, cKDTree\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a837e43d-7f1c-40aa-b8f0-a66d430c4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Version: 2.0.3\n"
     ]
    }
   ],
   "source": [
    "# Print library versions\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab7f98f8-970d-4ac0-9b35-a3fbe9dd6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Voxel Grid Construction for Point Cloud\n",
    "# ==========================================\n",
    "\n",
    "def create_voxel_grid(point_cloud, voxel_size):\n",
    "    \"\"\"\n",
    "    Construct a voxel grid for a given point cloud.\n",
    "    \n",
    "    Parameters:\n",
    "    - point_cloud: Open3D point cloud object.\n",
    "    - voxel_size: float, size of each voxel.\n",
    "\n",
    "    Returns:\n",
    "    - voxel_grid: dict, mapping voxel indices to lists of point indices.\n",
    "    \"\"\"\n",
    "    points_np = np.asarray(point_cloud.points)\n",
    "    min_bound = np.min(points_np, axis=0)\n",
    "\n",
    "    # Compute voxel indices using vectorized operations\n",
    "    voxel_indices = np.floor((points_np - min_bound) / voxel_size).astype(int)\n",
    "\n",
    "    # Map voxel indices to corresponding point indices\n",
    "    voxel_grid = {}\n",
    "    for i, voxel_index in enumerate(map(tuple, voxel_indices)):\n",
    "        voxel_grid.setdefault(voxel_index, []).append(i)\n",
    "\n",
    "    return voxel_grid\n",
    "\n",
    "def calculate_voxel_centers(point_cloud, voxel_grid):\n",
    "    \"\"\"\n",
    "    Compute the gravity center of each voxel in a voxelized point cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - point_cloud: Open3D point cloud object.\n",
    "    - voxel_grid: dict, mapping voxel indices to point indices.\n",
    "\n",
    "    Returns:\n",
    "    - voxel_centers: dict, mapping voxel indices to their computed centers.\n",
    "    \"\"\"\n",
    "    points_np = np.asarray(point_cloud.points)\n",
    "    voxel_centers = {}\n",
    "\n",
    "    for voxel_index, point_indices in voxel_grid.items():\n",
    "        points = points_np[point_indices]  \n",
    "        gravity_center = np.mean(points, axis=0)\n",
    "        voxel_centers[voxel_index] = gravity_center\n",
    "\n",
    "    return voxel_centers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80184a1-835f-4338-bb6f-e2d4cec3dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Correspondence Matching Between TLS & DLS\n",
    "# ==========================================\n",
    "\n",
    "def find_correspondences(tls_points, dls_points):\n",
    "    \"\"\"\n",
    "    Identify the nearest neighbor correspondences between TLS and DLS points.\n",
    "\n",
    "    Parameters:\n",
    "    - tls_points: np.array (Nx3), TLS point cloud.\n",
    "    - dls_points: np.array (Mx3), DLS point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - correspondences: dict, containing matched TLS and DLS indices.\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(dls_points)\n",
    "    distances, indices = nbrs.kneighbors(tls_points)\n",
    "\n",
    "    return {'tls_indices': np.arange(len(tls_points)), 'dls_indices': indices.flatten()}\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# Rigid Transformation Estimation\n",
    "# ==========================================\n",
    "\n",
    "def estimate_transformation(correspondences, tls_valid_p, dls_valid_p):\n",
    "    \"\"\"\n",
    "    Estimate the rigid transformation (rotation + translation) between TLS and DLS.\n",
    "\n",
    "    Parameters:\n",
    "    - correspondences: dict, matched indices of TLS and DLS points.\n",
    "    - tls_valid_p: np.array (Nx3), TLS points participating in alignment.\n",
    "    - dls_valid_p: np.array (Nx3), DLS points participating in alignment.\n",
    "\n",
    "    Returns:\n",
    "    - transformation: np.array (4x4), transformation matrix.\n",
    "    \"\"\"\n",
    "    tls_indices = correspondences['tls_indices']\n",
    "    dls_indices = correspondences['dls_indices']\n",
    "\n",
    "    # Extract matched point pairs\n",
    "    dls_points_matched = np.array(dls_valid_p)[dls_indices]\n",
    "    tls_points_matched = np.array(tls_valid_p)[tls_indices]\n",
    "\n",
    "    # Compute centroids\n",
    "    centroid_dls = np.mean(dls_points_matched, axis=0)\n",
    "    centroid_tls = np.mean(tls_points_matched, axis=0)\n",
    "\n",
    "    # Compute covariance matrix H\n",
    "    H = np.dot((dls_points_matched - centroid_dls).T, (tls_points_matched - centroid_tls))\n",
    "\n",
    "    # Compute SVD for rotation estimation\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # Ensure a proper rotation matrix (no reflection)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # Compute translation vector\n",
    "    t = centroid_tls - np.dot(R, centroid_dls)\n",
    "\n",
    "    # Construct final 4x4 transformation matrix\n",
    "    transformation = np.eye(4)\n",
    "    transformation[:3, :3] = R\n",
    "    transformation[:3, 3] = t\n",
    "\n",
    "    return transformation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Convergence Check for ICP\n",
    "# ==========================================\n",
    "\n",
    "def check_convergence(iteration, current_rmse):\n",
    "    \"\"\"\n",
    "    Check whether the ICP process has converged.\n",
    "\n",
    "    Parameters:\n",
    "    - iteration: int, current iteration number.\n",
    "    - current_rmse: float, root mean squared error at this iteration.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if convergence criteria are met.\n",
    "    \"\"\"\n",
    "    max_iterations = 15\n",
    "    threshold_rmse = 0.01  # Convergence threshold\n",
    "\n",
    "    return iteration >= max_iterations or current_rmse < threshold_rmse\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Axis-Angle Rotation to Rotation Matrix\n",
    "# ==========================================\n",
    "\n",
    "def axis_angle_to_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Convert an axis-angle representation to a rotation matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - axis: np.array (3,), rotation axis.\n",
    "    - theta: float, rotation angle in radians.\n",
    "\n",
    "    Returns:\n",
    "    - rot: np.array (3x3), rotation matrix.\n",
    "    \"\"\"\n",
    "    w = np.array([[0.0, -axis[2], axis[1]],\n",
    "                  [axis[2], 0.0, -axis[0]],\n",
    "                  [-axis[1], axis[0], 0.0]])\n",
    "    \n",
    "    rot = np.identity(3) + (np.sin(theta) * w) + ((1 - np.cos(theta)) * np.dot(w, w))\n",
    "    \n",
    "    return rot\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Gravity Center Distance Computation\n",
    "# ==========================================\n",
    "\n",
    "def calculate_distances(tls_gravity_points, dls_gravity_points):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distances between gravity centers of TLS and DLS.\n",
    "\n",
    "    Parameters:\n",
    "    - tls_gravity_points: dict, voxel centers for TLS.\n",
    "    - dls_gravity_points: dict, voxel centers for DLS.\n",
    "\n",
    "    Returns:\n",
    "    - distances: dict, mapping voxel indices to computed distances.\n",
    "    \"\"\"\n",
    "    distances = {}\n",
    "    \n",
    "    for voxel_index in tls_gravity_points.keys():\n",
    "        tls_gravity_center = tls_gravity_points[voxel_index]\n",
    "        dls_gravity_center = dls_gravity_points.get(voxel_index)\n",
    "\n",
    "        if dls_gravity_center is not None and dls_gravity_center.size > 0:\n",
    "            distance = np.linalg.norm(tls_gravity_center - dls_gravity_center)\n",
    "            distances[voxel_index] = distance\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ade9e8-f819-4528-af41-a79cd339302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Gravity Center Calculation for Voxelized Point Clouds\n",
    "# ==========================================\n",
    "\n",
    "# ==========================================\n",
    "# Optimized Gravity Center Calculation Using Sorted Search\n",
    "# ==========================================\n",
    "\n",
    "def calculate_gravity_centers_optimized(voxel_indices, tls_points, dls_points, min_bound):\n",
    "    \"\"\"\n",
    "    Optimized calculation of gravity centers for TLS and DLS points within each voxel using sorted search.\n",
    "\n",
    "    Parameters:\n",
    "    - voxel_indices: set, voxel indices with (x, y, z, size).\n",
    "    - tls_points: np.array (Nx3), TLS point cloud.\n",
    "    - dls_points: np.array (Mx3), DLS point cloud.\n",
    "    - min_bound: np.array (3,), minimum bound of the point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - tls_voxel_gravity_centers: dict, voxel indices mapped to TLS gravity centers.\n",
    "    - dls_voxel_gravity_centers: dict, voxel indices mapped to DLS gravity centers.\n",
    "    - vtls_points: dict, voxel-wise TLS points.\n",
    "    - vdls_points: dict, voxel-wise DLS points.\n",
    "    \"\"\"\n",
    "    tls_points = np.array(tls_points)\n",
    "    dls_points = np.array(dls_points)\n",
    "\n",
    "    # Pre-sort points along the x-axis for faster search\n",
    "    sorted_tlsp = tls_points[tls_points[:, 0].argsort()]\n",
    "    sorted_dlsp = dls_points[dls_points[:, 0].argsort()]\n",
    "\n",
    "    tls_voxel_gravity_centers = {}\n",
    "    dls_voxel_gravity_centers = {}\n",
    "    vtls_points = {}\n",
    "    vdls_points = {}\n",
    "\n",
    "    for voxel_index in voxel_indices:\n",
    "        size = voxel_index[3]\n",
    "\n",
    "        # Compute voxel boundaries\n",
    "        x_min, x_max = voxel_index[0] * voxel_default_size + min_bound[0], voxel_index[0] * voxel_default_size + min_bound[0] + size\n",
    "        y_min, y_max = voxel_index[1] * voxel_default_size + min_bound[1], voxel_index[1] * voxel_default_size + min_bound[1] + size\n",
    "        z_min, z_max = voxel_index[2] * voxel_default_size + min_bound[2], voxel_index[2] * voxel_default_size + min_bound[2] + size\n",
    "\n",
    "        # Retrieve points within the voxel using sorted search\n",
    "        voxel_tls_points = find_points_in_voxel(sorted_tlsp, x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "        voxel_dls_points = find_points_in_voxel(sorted_dlsp, x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "\n",
    "        vtls_points[voxel_index] = voxel_tls_points\n",
    "        vdls_points[voxel_index] = voxel_dls_points\n",
    "\n",
    "        # Compute and store gravity centers\n",
    "        if len(voxel_tls_points) > 0:\n",
    "            tls_voxel_gravity_centers[voxel_index] = np.mean(voxel_tls_points, axis=0)\n",
    "        if len(voxel_dls_points) > 0:\n",
    "            dls_voxel_gravity_centers[voxel_index] = np.mean(voxel_dls_points, axis=0)\n",
    "\n",
    "    return tls_voxel_gravity_centers, dls_voxel_gravity_centers, vtls_points, vdls_points\n",
    "\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# Optimized Point Search Within Voxel\n",
    "# ==========================================\n",
    "\n",
    "def find_points_in_voxel(sorted_points, x_min, x_max, y_min, y_max, z_min, z_max):\n",
    "    \"\"\"\n",
    "    Optimized point retrieval from a sorted point cloud within voxel boundaries using binary search.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_points: np.array (Nx3), pre-sorted point cloud.\n",
    "    - x_min, x_max, y_min, y_max, z_min, z_max: float, voxel boundaries.\n",
    "\n",
    "    Returns:\n",
    "    - voxel_points: np.array (Px3), points within the voxel.\n",
    "    \"\"\"\n",
    "    sorted_points = sorted_points[sorted_points[:, 0].argsort()]\n",
    "\n",
    "    # Binary search for x-coordinates\n",
    "    x_min_index = np.searchsorted(sorted_points[:, 0], x_min, side='right')\n",
    "    x_max_index = np.searchsorted(sorted_points[:, 0], x_max, side='left')\n",
    "    x_range_points = sorted_points[x_min_index:x_max_index]\n",
    "\n",
    "    # Binary search for y-coordinates\n",
    "    x_range_points = x_range_points[x_range_points[:, 1].argsort()]\n",
    "    y_min_index = np.searchsorted(x_range_points[:, 1], y_min, side='right')\n",
    "    y_max_index = np.searchsorted(x_range_points[:, 1], y_max, side='left')\n",
    "    y_range_points = x_range_points[y_min_index:y_max_index]\n",
    "\n",
    "    # Binary search for z-coordinates\n",
    "    y_range_points = y_range_points[y_range_points[:, 2].argsort()]\n",
    "    z_min_index = np.searchsorted(y_range_points[:, 2], z_min, side='right')\n",
    "    z_max_index = np.searchsorted(y_range_points[:, 2], z_max, side='left')\n",
    "    voxel_points = y_range_points[z_min_index:z_max_index]\n",
    "\n",
    "    return voxel_points\n",
    "\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# Confidence Determination for Voxels\n",
    "# ==========================================\n",
    "\n",
    "def determine_confidence(voxel_distances, voxels_with_sizes):\n",
    "    \"\"\"\n",
    "    Determine the confidence level of each voxel based on gravity center distances.\n",
    "\n",
    "    Parameters:\n",
    "    - voxel_distances: dict, mapping voxel indices to computed distances.\n",
    "    - voxels_with_sizes: set, voxel indices with sizes.\n",
    "\n",
    "    Returns:\n",
    "    - confident_voxels: set, voxels considered reliable.\n",
    "    - unconfident_voxels: set, voxels that require refinement.\n",
    "    \"\"\"\n",
    "    confident_voxels = set()\n",
    "    unconfident_voxels = set()\n",
    "\n",
    "    for voxel in voxels_with_sizes:\n",
    "        distance = voxel_distances.get(voxel, float('inf'))\n",
    "        threshold = (np.sqrt(3) / 4) * voxel[3]  # Adaptive threshold\n",
    "\n",
    "        if distance <= threshold:\n",
    "            confident_voxels.add(voxel)\n",
    "        else:\n",
    "            unconfident_voxels.add(voxel)\n",
    "\n",
    "    return confident_voxels, unconfident_voxels\n",
    "\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# Splitting and Filtering Voxels for Fine Registration\n",
    "# ==========================================\n",
    "\n",
    "def split_voxels(unconfident_voxels, updated_voxels, voxel_default_size):\n",
    "    \"\"\"\n",
    "    Subdivide unconfident voxels into smaller voxels to improve alignment precision.\n",
    "\n",
    "    Parameters:\n",
    "    - unconfident_voxels: set, indices of voxels deemed unreliable.\n",
    "    - updated_voxels: set, the full set of current voxels.\n",
    "    - voxel_default_size: float, the base voxel size.\n",
    "\n",
    "    Returns:\n",
    "    - updated_voxels: set, updated voxel indices after splitting.\n",
    "    - unconfident_voxels_copy: set, the new unconfident voxels.\n",
    "    \"\"\"\n",
    "    unconfident_voxels_copy = set(unconfident_voxels)  # Duplicate unconfident voxel set to modify safely\n",
    "\n",
    "    for voxel in unconfident_voxels:\n",
    "        i, j, k, voxel_size = voxel\n",
    "\n",
    "        # Remove the original unconfident voxel\n",
    "        updated_voxels.remove(voxel)\n",
    "        unconfident_voxels_copy.remove(voxel)\n",
    "\n",
    "        # Compute new voxel size after subdivision\n",
    "        new_size = voxel_size / 2.0\n",
    "        size_ratio = new_size / voxel_default_size\n",
    "\n",
    "        # Generate 8 sub-voxels by splitting along each axis\n",
    "        for di in range(2):\n",
    "            for dj in range(2):\n",
    "                for dk in range(2):\n",
    "                    new_voxel_index = (i + di * size_ratio, j + dj * size_ratio, k + dk * size_ratio, new_size)\n",
    "                    updated_voxels.add(new_voxel_index)\n",
    "\n",
    "    return updated_voxels, unconfident_voxels_copy\n",
    "\n",
    "\n",
    "def filter_splitable_voxels(unconfident_voxels, min_voxel_size):\n",
    "    \"\"\"\n",
    "    Identify unconfident voxels that can still be subdivided and those that are too small.\n",
    "\n",
    "    Parameters:\n",
    "    - unconfident_voxels: set, indices of voxels deemed unreliable.\n",
    "    - min_voxel_size: float, minimum allowable voxel size.\n",
    "\n",
    "    Returns:\n",
    "    - splitable_voxels: set, voxels that can still be subdivided.\n",
    "    - non_splitable_voxels: set, voxels that are too small to split further.\n",
    "    \"\"\"\n",
    "    splitable_voxels = set()\n",
    "    non_splitable_voxels = set()\n",
    "\n",
    "    for voxel in unconfident_voxels:\n",
    "        if voxel[3] > min_voxel_size:\n",
    "            splitable_voxels.add(voxel)\n",
    "        else:\n",
    "            non_splitable_voxels.add(voxel)\n",
    "\n",
    "    return splitable_voxels, non_splitable_voxels\n",
    "\n",
    "\n",
    "def filter_points_by_voxels(tls_points, dls_points, confident_voxels, voxel_default_size, min_bound):\n",
    "    \"\"\"\n",
    "    Extract points from TLS and DLS clouds that fall within confident voxels.\n",
    "\n",
    "    Parameters:\n",
    "    - tls_points: np.array (Nx3), TLS point cloud.\n",
    "    - dls_points: np.array (Mx3), DLS point cloud.\n",
    "    - confident_voxels: set, indices of reliable voxels.\n",
    "    - voxel_default_size: float, base voxel size.\n",
    "    - min_bound: np.array (3,), minimum bound of the point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - conf_tls_points: list, filtered TLS points within confident voxels.\n",
    "    - conf_dls_points: list, filtered DLS points within confident voxels.\n",
    "    \"\"\"\n",
    "    conf_tls_points = []\n",
    "    conf_dls_points = []\n",
    "\n",
    "    tls_points_np = np.array(tls_points)\n",
    "    dls_points_np = np.array(dls_points)\n",
    "\n",
    "    for voxel_index in confident_voxels:\n",
    "        size = voxel_index[-1]\n",
    "\n",
    "        # Compute voxel boundaries\n",
    "        x_min, x_max = voxel_index[0] * voxel_default_size + min_bound[0], voxel_index[0] * voxel_default_size + size + min_bound[0]\n",
    "        y_min, y_max = voxel_index[1] * voxel_default_size + min_bound[1], voxel_index[1] * voxel_default_size + size + min_bound[1]\n",
    "        z_min, z_max = voxel_index[2] * voxel_default_size + min_bound[2], voxel_index[2] * voxel_default_size + size + min_bound[2]\n",
    "\n",
    "        # Extract TLS points within voxel\n",
    "        tls_mask = (tls_points_np[:, 0] >= x_min) & (tls_points_np[:, 0] <= x_max) & \\\n",
    "                   (tls_points_np[:, 1] >= y_min) & (tls_points_np[:, 1] <= y_max) & \\\n",
    "                   (tls_points_np[:, 2] >= z_min) & (tls_points_np[:, 2] <= z_max)\n",
    "        conf_tls_points.extend(tls_points_np[tls_mask].tolist())\n",
    "\n",
    "        # Extract DLS points within voxel\n",
    "        dls_mask = (dls_points_np[:, 0] >= x_min) & (dls_points_np[:, 0] <= x_max) & \\\n",
    "                   (dls_points_np[:, 1] >= y_min) & (dls_points_np[:, 1] <= y_max) & \\\n",
    "                   (dls_points_np[:, 2] >= z_min) & (dls_points_np[:, 2] <= z_max)\n",
    "        conf_dls_points.extend(dls_points_np[dls_mask].tolist())\n",
    "\n",
    "    return conf_tls_points, conf_dls_points\n",
    "\n",
    "\n",
    "def extract_confident_points(vtls_points, vdls_points, confident_voxels):\n",
    "    \"\"\"\n",
    "    Retrieve TLS and DLS points from confident voxels.\n",
    "\n",
    "    Parameters:\n",
    "    - vtls_points: dict, voxel-wise TLS point dictionary.\n",
    "    - vdls_points: dict, voxel-wise DLS point dictionary.\n",
    "    - confident_voxels: set, indices of reliable voxels.\n",
    "\n",
    "    Returns:\n",
    "    - conf_tls_points: np.array, TLS points from confident voxels.\n",
    "    - conf_dls_points: np.array, DLS points from confident voxels.\n",
    "    \"\"\"\n",
    "    conf_tls_points = []\n",
    "    conf_dls_points = []\n",
    "\n",
    "    for voxel_index in confident_voxels:\n",
    "        conf_tls_points.extend(vtls_points.get(voxel_index, []))\n",
    "        conf_dls_points.extend(vdls_points.get(voxel_index, []))\n",
    "\n",
    "    return np.array(conf_tls_points), np.array(conf_dls_points)\n",
    "\n",
    "    \n",
    "\n",
    "# ==========================================\n",
    "# Point Correspondence Matching and RMSE Calculation\n",
    "# ==========================================\n",
    "\n",
    "def calculate_matched_rmse(source_points, target_points):\n",
    "    \"\"\"\n",
    "    Compute the Root Mean Square Error (RMSE) between corresponding points.\n",
    "\n",
    "    Parameters:\n",
    "    - source_points: np.array (Nx3), source point cloud.\n",
    "    - target_points: np.array (Mx3), target point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - rmse: float, root mean square error between matched points.\n",
    "    \"\"\"\n",
    "    # Find nearest neighbors\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(target_points)\n",
    "    distances, indices = nbrs.kneighbors(source_points)\n",
    "\n",
    "    # Retrieve matched target points\n",
    "    matched_target_points = target_points[indices.flatten()]\n",
    "\n",
    "    # Compute RMSE\n",
    "    return np.sqrt(mean_squared_error(source_points, matched_target_points))\n",
    "\n",
    "\n",
    "def find_correspondences(tls_points, dls_points):\n",
    "    \"\"\"\n",
    "    Identify nearest neighbor correspondences between TLS and DLS points.\n",
    "\n",
    "    Parameters:\n",
    "    - tls_points: np.array (Nx3), TLS point cloud.\n",
    "    - dls_points: np.array (Mx3), DLS point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - correspondences: dict, mapping TLS indices to nearest DLS indices.\n",
    "    \"\"\"\n",
    "    # Find the nearest neighbors between TLS and DLS points\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(dls_points)\n",
    "    distances, indices = nbrs.kneighbors(tls_points)\n",
    "\n",
    "    return {'tls_indices': np.arange(len(tls_points)), 'dls_indices': indices.flatten()}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def apply_transformation(points, transformation):\n",
    "    \"\"\"\n",
    "    Apply a rigid transformation to a set of points.\n",
    "\n",
    "    Parameters:\n",
    "    - points: np.array (Nx3), input point cloud.\n",
    "    - transformation: np.array (4x4), transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "    - transformed_points: np.array (Nx3), transformed point cloud.\n",
    "    \"\"\"\n",
    "    return points @ transformation[:3, :3].T + transformation[:3, 3]\n",
    "\n",
    "\n",
    "def visualize_confident_points(tls_points, dls_points):\n",
    "    \"\"\"\n",
    "    Visualize confident TLS and DLS points using Open3D.\n",
    "\n",
    "    Parameters:\n",
    "    - tls_points: np.array (Nx3), TLS points identified as confident.\n",
    "    - dls_points: np.array (Mx3), DLS points identified as confident.\n",
    "\n",
    "    Visualization:\n",
    "    - TLS points are shown in red.\n",
    "    - DLS points are shown in green.\n",
    "    \"\"\"\n",
    "    tls_cloud = o3d.geometry.PointCloud()\n",
    "    tls_cloud.points = o3d.utility.Vector3dVector(tls_points)\n",
    "    tls_cloud.paint_uniform_color([1, 0, 0])  # Red for TLS\n",
    "\n",
    "    dls_cloud = o3d.geometry.PointCloud()\n",
    "    dls_cloud.points = o3d.utility.Vector3dVector(dls_points)\n",
    "    dls_cloud.paint_uniform_color([0, 1, 0])  # Green for DLS\n",
    "\n",
    "    o3d.visualization.draw_geometries([tls_cloud, dls_cloud])\n",
    "\n",
    "\n",
    "def generate_alpha_shape(raw_points, alpha):\n",
    "    \"\"\"\n",
    "    Generate an alpha shape (concave hull) from a given point cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - raw_points: np.array (Nx3), input point cloud.\n",
    "    - alpha: float, alpha radius parameter controlling shape smoothness.\n",
    "\n",
    "    Returns:\n",
    "    - alpha_shape: open3d.geometry.TriangleMesh, generated alpha shape.\n",
    "\n",
    "    Notes:\n",
    "    - Alpha shapes are useful for extracting object boundaries in point clouds.\n",
    "    - Smaller alpha values yield more detailed boundaries.\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(raw_points)\n",
    "\n",
    "    # Generate alpha shape\n",
    "    alpha_shape = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha)\n",
    "\n",
    "    return alpha_shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d447479-1cb7-4936-aa6c-5e78aa731773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_plane_icp_knn(source_points):\n",
    "    \"\"\"\n",
    "    Perform point-to-plane ICP using nearest neighbor search.\n",
    "\n",
    "    Parameters:\n",
    "    - source_points: np.array (Nx3), input source point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - transformation: np.array (4x4), estimated rigid transformation matrix.\n",
    "    - mean_distance: float, mean distance between matched points.\n",
    "    \"\"\"\n",
    "    closest_points = []\n",
    "    closest_triangle_normals = []\n",
    "    \n",
    "    for point in source_points:\n",
    "        query_point = o3d.core.Tensor([point], dtype=o3d.core.Dtype.Float32)\n",
    "        result = scene.compute_closest_points(query_point)\n",
    "        closest_points.append(result['points'].numpy()[0])\n",
    "        triangle_idx = result['primitive_ids'].numpy()[0]\n",
    "        closest_triangle_normals.append(np.asarray(triangles_normals)[triangle_idx])\n",
    "    \n",
    "    closest_points = np.array(closest_points)\n",
    "    closest_triangle_normals = np.array(closest_triangle_normals)\n",
    "    \n",
    "    np_pcd_s = np.array(source_points)\n",
    "    A = np.zeros((6, 6))\n",
    "    b = np.zeros((6, 1))\n",
    "    \n",
    "    for i in range(len(np_pcd_s)):\n",
    "        xn = np.cross(np_pcd_s[i], closest_triangle_normals[i])\n",
    "        xn_n = np.hstack((xn, closest_triangle_normals[i])).reshape(-1, 1)\n",
    "        A += np.dot(xn_n, xn_n.T)\n",
    "        \n",
    "        nT = closest_triangle_normals[i].reshape(1, -1)\n",
    "        p_x = (closest_points[i] - np_pcd_s[i]).reshape(-1, 1)\n",
    "        b += xn_n * np.dot(nT, p_x)\n",
    "\n",
    "    u_opt = np.linalg.solve(A, b)\n",
    "    theta = np.linalg.norm(u_opt[:3])\n",
    "    w = u_opt[:3].flatten() / theta\n",
    "    rot = axis_angle_to_matrix(w, theta)\n",
    "    \n",
    "    transformation = np.eye(4)\n",
    "    transformation[:3, :3] = rot\n",
    "    transformation[:3, 3] = u_opt[3:6].flatten()\n",
    "\n",
    "    distances = np.abs(np.sum((np_pcd_s - closest_points) * closest_triangle_normals, axis=1))\n",
    "    mean_distance = np.mean(distances)\n",
    "\n",
    "    return transformation, mean_distance\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def iterative_icp_process_pt2pl(tls_p, dls_p, initial_v, tls_ds_points, dls_ds_points, min_bound, voxel_default_size, max_iterations=15):\n",
    "    \"\"\"\n",
    "    Perform iterative point-to-plane ICP using voxel-based filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - tls_p: np.array (Nx3), TLS point cloud.\n",
    "    - dls_p: np.array (Mx3), DLS point cloud.\n",
    "    - initial_v: set, initial voxel indices for processing.\n",
    "    - tls_ds_points: np.array (Nx3), downsampled TLS points.\n",
    "    - dls_ds_points: np.array (Mx3), downsampled DLS points.\n",
    "    - min_bound: np.array (3,), minimum bounding box coordinates of the point cloud.\n",
    "    - voxel_default_size: float, initial voxel size.\n",
    "    - max_iterations: int, maximum iterations allowed.\n",
    "\n",
    "    Returns:\n",
    "    - transformation: np.array (4x4), estimated transformation matrix.\n",
    "    - iteration: int, number of iterations before convergence.\n",
    "    - final_confident_tls_points: np.array (Px3), final confident TLS points.\n",
    "    - final_confident_dls_points: np.array (Qx3), final confident DLS points.\n",
    "    \"\"\"\n",
    "    tls_ds_points = np.array(tls_ds_points)\n",
    "    dls_ds_points = np.array(dls_ds_points)\n",
    "    \n",
    "    converged = False\n",
    "    transformation = np.eye(4)\n",
    "    iteration = 0\n",
    "    updated_voxels = initial_v\n",
    "    final_confident_tls_points, final_confident_dls_points = [], []\n",
    "    \n",
    "    tls_gp, dls_gp, vtls_points, vdls_points = calculate_gravity_centers_optimized(updated_voxels, tls_ds_points, dls_ds_points, min_bound)\n",
    "    print('Initial voxel count TLS:', len(vtls_points.keys()), 'DLS:', len(vdls_points.keys()))\n",
    "    \n",
    "    while not converged:\n",
    "        vdist_icp = calculate_distances(tls_gp, dls_gp)\n",
    "        conf_v_icp, unconf_v_icp = determine_confidence(vdist_icp, updated_voxels)\n",
    "        print('Confident and unconfident before splitting:', len(conf_v_icp), len(unconf_v_icp))\n",
    "        \n",
    "        splitable_voxels, _ = filter_splitable_voxels(unconf_v_icp, MIN_VOXEL_SIZE)\n",
    "        updated_voxels, _ = split_voxels(splitable_voxels, updated_voxels, voxel_default_size)\n",
    "        \n",
    "        if len(conf_v_icp) == 0:\n",
    "            continue\n",
    "        \n",
    "        conf_tlsp_icp, conf_dlsp_icp = extract_confident_points(vtls_points, vdls_points, conf_v_icp)\n",
    "        conf_tlsp_icp = np.array(conf_tlsp_icp)\n",
    "        conf_dlsp_icp = np.array(conf_dlsp_icp)\n",
    "        print('Confident TLS:', len(conf_tlsp_icp), 'Confident DLS:', len(conf_dlsp_icp))\n",
    "        \n",
    "        transformation, pt2pl_rmse = point_to_plane_icp_knn(conf_dlsp_icp)\n",
    "        conf_dlsp_icp = apply_transformation(conf_dlsp_icp, transformation)\n",
    "        \n",
    "        dls_ds_points = apply_transformation(dls_ds_points, transformation)\n",
    "        \n",
    "        tls_gp, dls_gp, vtls_points, vdls_points = calculate_gravity_centers_optimized(updated_voxels, tls_ds_points, dls_ds_points, min_bound)\n",
    "        \n",
    "        pt2pt_rmse = calculate_matched_rmse(conf_dlsp_icp, conf_tlsp_icp)\n",
    "        \n",
    "        converged = check_convergence(iteration, pt2pl_rmse)\n",
    "        \n",
    "        if converged:\n",
    "            print('FINISHED. pt2ptRMSE:', pt2pt_rmse, 'pt2plRMSE:', pt2pl_rmse)\n",
    "            final_confident_tls_points, final_confident_dls_points = conf_tlsp_icp, conf_dlsp_icp\n",
    "            break\n",
    "        \n",
    "        iteration += 1\n",
    "        print('Iteration:', iteration, 'pt2ptRMSE:', pt2pt_rmse, 'pt2plRMSE:', pt2pl_rmse)\n",
    "\n",
    "    return transformation, iteration, final_confident_tls_points, final_confident_dls_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db24b7-b56d-47e4-80a8-3d6d775629a4",
   "metadata": {},
   "source": [
    "## Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceaa8f4-14b6-400a-a7bf-998ef5898573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" \n",
    "    Main function to execute fine alignment using point-to-mesh ICP.\n",
    "    \n",
    "    The workflow consists of:\n",
    "    \n",
    "    1. Loading TLS and DLS point clouds.\n",
    "    2. Constructing voxel grids to divide the point cloud space.\n",
    "    3. Computing gravity centers of voxels for initial alignment.\n",
    "    4. Identifying intersecting voxels between TLS and DLS.\n",
    "    5. Generating an Alpha Shape for TLS to provide a reference surface.\n",
    "    6. Using a raycasting scene to extract surface normals.\n",
    "    7. Performing iterative point-to-plane ICP:\n",
    "        - Identifying confident regions using voxel distances.\n",
    "        - Refining voxels by splitting unconfident ones.\n",
    "        - Updating transformations iteratively.\n",
    "    8. Computing the final transformation matrix.\n",
    "    9. Visualizing the final confident point correspondences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load TLS and DLS point clouds after coarse alignment\n",
    "    tls_raw = o3d.io.read_point_cloud(\"your_path_to_TLS_point_cloud_after_coarse_alignment.pcd\")\n",
    "    dls_raw = o3d.io.read_point_cloud(\"your_path_to_DLS_point_cloud_after_coarse_alignment.pcd\")\n",
    "\n",
    "    # Define voxelization parameters\n",
    "    voxel_size = 0.5  # Coarse voxel grid\n",
    "    voxel_size_ds = 0.001  # Fine voxel size for downsampling\n",
    "\n",
    "    # Construct voxel grids for TLS and DLS\n",
    "    tls_voxel_grid = create_voxel_grid(tls_raw, voxel_size)\n",
    "    dls_voxel_grid = create_voxel_grid(dls_raw, voxel_size)\n",
    "\n",
    "    # Compute gravity centers for each voxel\n",
    "    tls_voxel_centers = calculate_voxel_centers(tls_raw, tls_voxel_grid)\n",
    "    dls_voxel_centers = calculate_voxel_centers(dls_raw, dls_voxel_grid)\n",
    "\n",
    "    # Merge TLS and DLS point clouds to find the minimum boundary\n",
    "    merged_cloud = tls_raw + dls_raw\n",
    "    min_bound = np.min(np.asarray(merged_cloud.points), axis=0)\n",
    "\n",
    "    # Identify intersecting voxels between TLS and DLS\n",
    "    tls_keys = set(tls_voxel_grid.keys())\n",
    "    dls_keys = set(dls_voxel_grid.keys())\n",
    "    intersection_keys = tls_keys.intersection(dls_keys)\n",
    "\n",
    "    # Generate Alpha Shape for TLS to define its surface\n",
    "    tls_alpha_shape = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(tls_raw, alpha=0.05)\n",
    "    tls_alpha_shape.compute_triangle_normals()\n",
    "\n",
    "    # Extract mesh triangles and surface normals for point-to-plane ICP\n",
    "    triangles = tls_alpha_shape.triangles\n",
    "    triangles_normals = tls_alpha_shape.triangle_normals\n",
    "\n",
    "    # Convert Alpha Shape to Open3D tensor format for raycasting\n",
    "    tls_alpha_t = o3d.t.geometry.TriangleMesh.from_legacy(tls_alpha_shape)\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    mesh_id = scene.add_triangles(tls_alpha_t)\n",
    "\n",
    "    # Define voxel parameters for hierarchical refinement\n",
    "    voxel_default_size = voxel_size\n",
    "    MIN_VOXEL_SIZE = voxel_default_size / (2 ** 4)  # Minimum voxel size for refinement\n",
    "\n",
    "    # Convert TLS and DLS point clouds to NumPy arrays for efficient processing\n",
    "    tls_points_np = np.asarray(tls_raw.points)\n",
    "    dls_points_np = np.asarray(dls_raw.points)\n",
    "\n",
    "    # Identify intersecting voxel centers for initial alignment\n",
    "    intersection_voxels = set(tls_voxel_centers.keys()) & set(dls_voxel_centers.keys())\n",
    "\n",
    "    # Initialize voxel dataset, each voxel represented by (x, y, z, voxel_size)\n",
    "    initial_voxels = {(x, y, z, voxel_default_size) for (x, y, z) in intersection_voxels}\n",
    "\n",
    "    # Compute gravity centers for initial alignment\n",
    "    tls_gp, dls_gp, vtls_points_gp, vdls_points_gp = calculate_gravity_centers_optimized(\n",
    "        initial_voxels, tls_points_np, dls_points_np, min_bound\n",
    "    )\n",
    "\n",
    "    # Compute distances between gravity centers to determine confident regions\n",
    "    vdist = calculate_distances(tls_gp, dls_gp)\n",
    "\n",
    "    # Perform iterative point-to-plane ICP with voxel refinement\n",
    "    transformation, num_iterations, confident_tls_points, confident_dls_points = iterative_icp_process_pt2pl(\n",
    "        tls_points_np, dls_points_np, initial_voxels, tls_points_np, dls_points_np, \n",
    "        min_bound, voxel_default_size, max_iterations=15\n",
    "    )\n",
    "\n",
    "    # Output the final transformation matrix\n",
    "    print(\"Final Transformation Matrix:\")\n",
    "    print(transformation)\n",
    "    print(f\"Converged in {num_iterations} Iterations\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e2454-3fd8-472a-8370-42bb1e4ef3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
